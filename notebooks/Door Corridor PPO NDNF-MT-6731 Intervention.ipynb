{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import json\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from typing import Any\n",
    "import warnings\n",
    "from IPython.display import Video\n",
    "\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clingo\n",
    "import gymnasium as gym\n",
    "from gymnasium.wrappers import RecordVideo\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common import synthesize\n",
    "from corridor_grid.envs import (\n",
    "    DoorCorridorEnv,\n",
    "    DoorCorridorTEnv,\n",
    "    DoorCorridorOTEnv,\n",
    ")\n",
    "from door_corridor_ppo import construct_model, make_env, DCPPONDNFMutexTanhAgent\n",
    "from eval.door_corridor_ppo_ndnf_mt_multirun_eval import (\n",
    "    get_ndnf_action,\n",
    "    simulate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dc5_ppo_ndnf_mt_k1eoc4_tanh_exl16_3e5_aux_6731\n"
     ]
    }
   ],
   "source": [
    "MODEL_SEED = 6731\n",
    "\n",
    "model_name = f\"dc5_ppo_ndnf_mt_k1eoc4_tanh_exl16_3e5_aux_{MODEL_SEED}\"\n",
    "print(model_name)\n",
    "\n",
    "model_cfg = {\n",
    "    \"experiment_name\": \"dc5_ppo_ndnf_mt_k1eoc4_tanh_exl16_3e5_aux\",\n",
    "    \"customised_image_encoder\": {\n",
    "        \"encoder_output_chanel\": 4,\n",
    "        \"last_act\": \"tanh\",\n",
    "        \"kernel_size\": 1,\n",
    "        \"use_extra_layer\": True,\n",
    "        \"extra_layer_out\": 16,\n",
    "        \"extra_layer_use_bias\": True,\n",
    "    },\n",
    "    \"use_eo\": False,\n",
    "    \"use_mt\": True,\n",
    "    \"use_argmax_to_choose_action\": True,\n",
    "    \"discretise_img_encoding\": True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_PROCESSES = 8\n",
    "NUM_EPISODES = 100\n",
    "DEVICE = torch.device(\"cpu\")\n",
    "\n",
    "BASE_STORAGE_DIR = Path(\"../dc_ppo_storage\")\n",
    "single_env = DoorCorridorEnv(render_mode=\"rgb_array\")\n",
    "envs = gym.vector.SyncVectorEnv(\n",
    "    [make_env(i, i, False) for i in range(NUM_PROCESSES)]\n",
    ")\n",
    "\n",
    "simulate = lambda action_fn: simulate_fn(envs, action_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original Model and DoorCorridorEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded!\n",
      "DCPPONDNFMutexTanhAgent(\n",
      "  (image_encoder): Sequential(\n",
      "    (0): Conv2d(2, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): Tanh()\n",
      "  )\n",
      "  (extra_layer): Sequential(\n",
      "    (0): Linear(in_features=36, out_features=16, bias=True)\n",
      "    (1): Tanh()\n",
      "  )\n",
      "  (actor): NeuralDNFMutexTanh(\n",
      "    (conjunctions): SemiSymbolic(in_features=16, out_features=12, layer_type=SemiSymbolicLayerType.CONJUNCTION,current_delta=1.00)\n",
      "    (disjunctions): SemiSymbolicMutexTanh(in_features=12, out_features=4, layer_type=SemiSymbolicLayerType.DISJUNCTION,current_delta=1.00)\n",
      "  )\n",
      "  (critic): Sequential(\n",
      "    (0): Linear(in_features=16, out_features=64, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=64, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_dir = BASE_STORAGE_DIR / model_name\n",
    "model: DCPPONDNFMutexTanhAgent = construct_model(\n",
    "    model_cfg, # type: ignore\n",
    "    DoorCorridorEnv.get_num_actions(),\n",
    "    True,\n",
    "    single_env.observation_space[\"image\"],  # type: ignore\n",
    ")\n",
    "model.to(DEVICE)\n",
    "model_state = torch.load(\n",
    "    model_dir / \"thresholded_model.pth\", map_location=DEVICE\n",
    ")\n",
    "model.load_state_dict(model_state)\n",
    "model.eval()\n",
    "\n",
    "print(\"Model loaded!\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ndnf_mt_dis_action_fn = lambda obs: get_ndnf_action(model, True, obs)\n",
    "\n",
    "\n",
    "def _simulate_with_print(action_fn, model_name: str) -> dict[str, Any]:\n",
    "    logs = simulate(action_fn)\n",
    "\n",
    "    num_frames = sum(logs[\"num_frames_per_episode\"])\n",
    "    return_per_episode = synthesize(logs[\"return_per_episode\"])\n",
    "    num_frames_per_episode = synthesize(logs[\"num_frames_per_episode\"])\n",
    "\n",
    "    print(\n",
    "        \"{}\\tF {} | R:μσmM {:.2f} {:.2f} {:.2f} {:.2f} | F:μσmM {:.1f} {:.1f} {} {}\".format(\n",
    "            model_name,\n",
    "            num_frames,\n",
    "            *return_per_episode.values(),\n",
    "            *num_frames_per_episode.values(),\n",
    "        )\n",
    "    )\n",
    "    print(f\"Mutual exclusivity: {logs['mutual_exclusivity']}\")\n",
    "    print(f\"Missing actions: {logs['missing_actions']}\")\n",
    "    return logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDNF-MT final model\tF 832.0 | R:μσmM -8.00 0.00 -8.00 -8.00 | F:μσmM 8.0 0.0 8.0 8.0\n",
      "Mutual exclusivity: True\n",
      "Missing actions: False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_simulate_with_print(_ndnf_mt_dis_action_fn, \"NDNF-MT final model\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a_1.', 'a_2.', 'a_6.', 'a_8.', 'a_13.']\n",
      "['a_1.', 'a_2.', 'a_5.', 'a_6.', 'a_8.', 'a_9.', 'a_10.', 'a_13.']\n",
      "['a_2.', 'a_6.', 'a_10.']\n",
      "['a_1.', 'a_2.', 'a_5.', 'a_6.', 'a_7.', 'a_8.', 'a_9.', 'a_10.', 'a_13.', 'a_14.']\n",
      "['a_2.', 'a_6.', 'a_7.', 'a_10.', 'a_14.']\n",
      "['a_1.', 'a_2.', 'a_5.', 'a_6.', 'a_7.', 'a_8.', 'a_9.', 'a_10.', 'a_13.', 'a_14.']\n",
      "['a_2.', 'a_6.', 'a_7.', 'a_11.', 'a_14.', 'a_15.']\n",
      "['a_2.', 'a_6.', 'a_7.', 'a_11.', 'a_13.', 'a_14.']\n"
     ]
    }
   ],
   "source": [
    "obs, _ = single_env.reset()\n",
    "\n",
    "terminated = False\n",
    "truncated = False\n",
    "reward_sum = 0\n",
    "\n",
    "while not terminated and not truncated:\n",
    "    with torch.no_grad():\n",
    "        raw_img_encoding = model.get_img_encoding(\n",
    "            preprocessed_obs={\n",
    "                \"image\": torch.tensor(obs[\"image\"].copy(), device=DEVICE)\n",
    "                .unsqueeze(0)\n",
    "                .float()\n",
    "            }\n",
    "        ).squeeze(0)\n",
    "        actions = model.get_actions(\n",
    "            preprocessed_obs={\n",
    "                \"image\": torch.tensor(obs[\"image\"].copy(), device=DEVICE)\n",
    "                .unsqueeze(0)\n",
    "                .float()\n",
    "            }\n",
    "        )\n",
    "    img_encoding = [\n",
    "        f\"a_{a.item()}.\" for a in torch.nonzero(raw_img_encoding > 0)\n",
    "    ]\n",
    "    print(img_encoding)\n",
    "    obs, reward, terminated, truncated, _ = single_env.step(actions[0].item())\n",
    "    reward_sum += reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASP rules:\n",
      "disj_1 :- conj_5.\n",
      "disj_2 :- conj_4.\n",
      "disj_3 :- not conj_6.\n",
      "conj_4 :- not a_8.\n",
      "conj_5 :- not a_9, a_13, not a_14.\n",
      "conj_6 :- not a_9.\n",
      "\n",
      "Interpretation:\n",
      "a_8 :- top_right_corner_unseen.\n",
      "a_9 :- one_step_ahead_closed_door.\n",
      "a_13 :- not one_step_ahead_open_door.\n",
      "a_14 :- curr_location_open_door.\n"
     ]
    }
   ],
   "source": [
    "with open(model_dir / \"asp_rules.lp\", \"r\") as f:\n",
    "    asp_rules = list(filter(lambda s: s != \"\", f.read().split(\"\\n\")))\n",
    "\n",
    "print(\"ASP rules:\")\n",
    "for r in asp_rules:\n",
    "    print(r)\n",
    "\n",
    "print()\n",
    "print(\"Interpretation:\")\n",
    "with open(model_dir / \"interpret_result.json\", \"r\") as f:\n",
    "    interpret_result = json.load(f)\n",
    "interpretation = interpret_result[\"0\"][\"parsed_program\"]\n",
    "for r in interpretation:\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "turn_right :- not one_step_ahead_closed_door, not one_step_ahead_open_door, not curr_location_open_door.\n",
    "\n",
    "forward :- not top_right_corner_unseen.\n",
    "\n",
    "toggle :- one_step_ahead_closed_door. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NDNF-MT on Door Corridor T\n",
    "\n",
    "A modified version of `DoorCorridorEnv`, but to finish the environment, the\n",
    "agent must be in front of the goal state and toggle it instead of moving onto it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dct = DoorCorridorTEnv(render_mode=\"rgb_array\")\n",
    "dct.metadata[\"render_fps\"] = 1\n",
    "model.load_state_dict(model_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward: -270\n",
      "Terminated: False\n",
      "Truncated: True\n"
     ]
    }
   ],
   "source": [
    "obs, _ = dct.reset()\n",
    "\n",
    "terminated = False\n",
    "truncated = False\n",
    "reward_sum = 0\n",
    "\n",
    "while not terminated and not truncated:\n",
    "    with torch.no_grad():\n",
    "        actions = model.get_actions(\n",
    "            preprocessed_obs={\n",
    "                \"image\": torch.tensor([obs[\"image\"]], dtype=torch.float32).to(\n",
    "                    DEVICE\n",
    "                )\n",
    "            },\n",
    "            use_argmax=True,\n",
    "            discretise_img_encoding=True,\n",
    "        )\n",
    "    actions = actions[0]\n",
    "    obs, reward, terminated, truncated, _ = dct.step(actions[0])\n",
    "    reward_sum += reward\n",
    "\n",
    "print(f\"Reward: {reward_sum}\")\n",
    "print(f\"Terminated: {terminated}\")\n",
    "print(f\"Truncated: {truncated}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modified ASP rules:\n",
    "\n",
    "disj_1 :- conj_5.\n",
    "\n",
    "disj_2 :- conj_4.\n",
    "\n",
    "disj_3 :- not conj_6.\n",
    "\n",
    "**disj_3 :- conj_0.**\n",
    "\n",
    "**conj_0 :- a_11, a_13.**\n",
    "\n",
    "conj_4 :- not a_8, **not a_13**.\n",
    "\n",
    "conj_5 :- not a_9, a_13, not a_14.\n",
    "\n",
    "conj_6 :- not a_9.\n",
    "\n",
    "\n",
    "Image encoding at each timestep:\n",
    "\n",
    "0 ['a_1.', 'a_2.', 'a_6.', 'a_8.', 'a_13.']\n",
    "\n",
    "1 ['a_1.', 'a_2.', 'a_5.', 'a_6.', 'a_8.', 'a_9.', 'a_10.', 'a_13.']\n",
    "\n",
    "2 ['a_2.', 'a_6.', 'a_10.']\n",
    "\n",
    "3 ['a_1.', 'a_2.', 'a_5.', 'a_6.', 'a_7.', 'a_8.', 'a_9.', 'a_10.', 'a_13.', 'a_14.']\n",
    "\n",
    "4 ['a_2.', 'a_6.', 'a_7.', 'a_10.', 'a_14.']\n",
    "\n",
    "5 ['a_1.', 'a_2.', 'a_5.', 'a_6.', 'a_7.', 'a_8.', 'a_9.', 'a_10.', 'a_13.', 'a_14.']\n",
    "\n",
    "6 ['a_2.', 'a_6.', 'a_7.', 'a_11.', 'a_14.', 'a_15.']\n",
    "\n",
    "7 ['a_2.', 'a_6.', 'a_7.', 'a_11.', 'a_13.', 'a_14.']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a_1.', 'a_2.', 'a_6.', 'a_8.', 'a_13.']\n",
      "Action: 1\n",
      "['a_1.', 'a_2.', 'a_5.', 'a_6.', 'a_8.', 'a_9.', 'a_10.', 'a_13.']\n",
      "Action: 3\n",
      "['a_2.', 'a_6.', 'a_10.']\n",
      "Action: 2\n",
      "['a_1.', 'a_2.', 'a_5.', 'a_6.', 'a_7.', 'a_8.', 'a_9.', 'a_10.', 'a_13.', 'a_14.']\n",
      "Action: 3\n",
      "['a_2.', 'a_6.', 'a_7.', 'a_10.', 'a_14.']\n",
      "Action: 2\n",
      "['a_1.', 'a_2.', 'a_5.', 'a_6.', 'a_7.', 'a_8.', 'a_9.', 'a_10.', 'a_13.', 'a_14.']\n",
      "Action: 3\n",
      "['a_2.', 'a_6.', 'a_7.', 'a_11.', 'a_14.', 'a_15.']\n",
      "Action: 2\n",
      "['a_2.', 'a_6.', 'a_7.', 'a_11.', 'a_13.', 'a_14.']\n",
      "Action: 3\n",
      "Reward: -8\n",
      "Terminated: True\n",
      "Truncated: False\n"
     ]
    }
   ],
   "source": [
    "obs, _ = dct.reset()\n",
    "\n",
    "terminated = False\n",
    "truncated = False\n",
    "reward_sum = 0\n",
    "\n",
    "new_rules = [\n",
    "    \"disj_1 :- conj_5.\",\n",
    "    \"disj_2 :- conj_4.\",\n",
    "    \"disj_3 :- not conj_6.\",\n",
    "    \"disj_3 :- conj_0.\",\n",
    "    \"conj_4 :- not a_8, not a_13.\",\n",
    "    \"conj_5 :- not a_9, a_13, not a_14.\",\n",
    "    \"conj_6 :- not a_9.\",\n",
    "    \"conj_0 :- a_11, a_13.\",\n",
    "]\n",
    "\n",
    "while not terminated and not truncated:\n",
    "    with torch.no_grad():\n",
    "        raw_img_encoding = model.get_img_encoding(\n",
    "            preprocessed_obs={\n",
    "                \"image\": torch.tensor(obs[\"image\"].copy(), device=DEVICE)\n",
    "                .unsqueeze(0)\n",
    "                .float()\n",
    "            }\n",
    "        ).squeeze(0)\n",
    "    img_encoding = [\n",
    "        f\"a_{a.item()}.\" for a in torch.nonzero(raw_img_encoding > 0)\n",
    "    ]\n",
    "    print(img_encoding)\n",
    "    ctl = clingo.Control([\"--warn=none\"])\n",
    "    show_statements = [\n",
    "        f\"#show disj_{i}/0.\" for i in range(DoorCorridorEnv.get_num_actions())\n",
    "    ]\n",
    "    ctl.add(\"base\", [], \" \".join(img_encoding + show_statements + new_rules))\n",
    "    ctl.ground([(\"base\", [])])\n",
    "    with ctl.solve(yield_=True) as handle:  # type: ignore\n",
    "        all_answer_sets = [str(a) for a in handle]\n",
    "\n",
    "    if len(all_answer_sets) != 1:\n",
    "        # No model or multiple answer sets, should not happen\n",
    "        print(f\"No model or multiple answer sets when evaluating rules.\")\n",
    "        break\n",
    "\n",
    "    if all_answer_sets[0] == \"\":\n",
    "        print(f\"No output action!\")\n",
    "        break\n",
    "\n",
    "    output_classes = all_answer_sets[0].split(\" \")\n",
    "    if len(output_classes) == 0:\n",
    "        print(f\"No output action!\")\n",
    "        break\n",
    "    output_classes_set = set([int(o[5:]) for o in output_classes])\n",
    "\n",
    "    if len(output_classes_set) != 1:\n",
    "        print(f\"Output set: {output_classes_set} not exactly one item!\")\n",
    "        break\n",
    "\n",
    "    action = list(output_classes_set)[0]\n",
    "    print(f\"Action: {action}\")\n",
    "    obs, reward, terminated, truncated, _ = dct.step(action)\n",
    "    reward_sum += reward\n",
    "\n",
    "print(f\"Reward: {reward_sum}\")\n",
    "print(f\"Terminated: {terminated}\")\n",
    "print(f\"Truncated: {truncated}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify the model and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_sd = deepcopy(model_state)\n",
    "modified_sd[\"actor.conjunctions.weights\"][0] *= 0\n",
    "modified_sd[\"actor.conjunctions.weights\"][0, 11] = 6\n",
    "modified_sd[\"actor.conjunctions.weights\"][0, 13] = 6\n",
    "modified_sd[\"actor.conjunctions.weights\"][4] *= 0\n",
    "modified_sd[\"actor.conjunctions.weights\"][4, 8] = -6\n",
    "modified_sd[\"actor.conjunctions.weights\"][4, 13] = -6\n",
    "\n",
    "\n",
    "modified_sd[\"actor.disjunctions.weights\"][3, 0] = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DCPPONDNFMutexTanhAgent(\n",
       "  (image_encoder): Sequential(\n",
       "    (0): Conv2d(2, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (1): Tanh()\n",
       "  )\n",
       "  (extra_layer): Sequential(\n",
       "    (0): Linear(in_features=36, out_features=16, bias=True)\n",
       "    (1): Tanh()\n",
       "  )\n",
       "  (actor): NeuralDNFMutexTanh(\n",
       "    (conjunctions): SemiSymbolic(in_features=16, out_features=12, layer_type=SemiSymbolicLayerType.CONJUNCTION,current_delta=1.00)\n",
       "    (disjunctions): SemiSymbolicMutexTanh(in_features=12, out_features=4, layer_type=SemiSymbolicLayerType.DISJUNCTION,current_delta=1.00)\n",
       "  )\n",
       "  (critic): Sequential(\n",
       "    (0): Linear(in_features=16, out_features=64, bias=True)\n",
       "    (1): Tanh()\n",
       "    (2): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dct_model: DCPPONDNFMutexTanhAgent = construct_model(\n",
    "    model_cfg, # type: ignore\n",
    "    DoorCorridorEnv.get_num_actions(),\n",
    "    True,\n",
    "    single_env.observation_space[\"image\"],  # type: ignore\n",
    ")\n",
    "dct_model.to(DEVICE)\n",
    "dct_model.load_state_dict(modified_sd)\n",
    "dct_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward: -8\n",
      "Terminated: True\n",
      "Truncated: False\n"
     ]
    }
   ],
   "source": [
    "obs, _ = dct.reset()\n",
    "\n",
    "terminated = False\n",
    "truncated = False\n",
    "reward_sum = 0\n",
    "\n",
    "while not terminated and not truncated:\n",
    "    with torch.no_grad():\n",
    "        actions = dct_model.get_actions(\n",
    "            preprocessed_obs={\n",
    "                \"image\": torch.tensor([obs[\"image\"]], dtype=torch.float32).to(\n",
    "                    DEVICE\n",
    "                )\n",
    "            },\n",
    "            use_argmax=True,\n",
    "            discretise_img_encoding=True,\n",
    "        )\n",
    "    actions = actions[0]\n",
    "    obs, reward, terminated, truncated, _ = dct.step(actions[0])\n",
    "    reward_sum += reward\n",
    "\n",
    "print(f\"Reward: {reward_sum}\")\n",
    "print(f\"Terminated: {terminated}\")\n",
    "print(f\"Truncated: {truncated}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Record the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a_1.', 'a_2.', 'a_6.', 'a_8.', 'a_13.']\n",
      "Action: 1\n",
      "['a_1.', 'a_2.', 'a_5.', 'a_6.', 'a_8.', 'a_9.', 'a_10.', 'a_13.']\n",
      "Action: 3\n",
      "['a_2.', 'a_6.', 'a_10.']\n",
      "Action: 2\n",
      "['a_1.', 'a_2.', 'a_5.', 'a_6.', 'a_7.', 'a_8.', 'a_9.', 'a_10.', 'a_13.', 'a_14.']\n",
      "Action: 3\n",
      "['a_2.', 'a_6.', 'a_7.', 'a_10.', 'a_14.']\n",
      "Action: 2\n",
      "['a_1.', 'a_2.', 'a_5.', 'a_6.', 'a_7.', 'a_8.', 'a_9.', 'a_10.', 'a_13.', 'a_14.']\n",
      "Action: 3\n",
      "['a_2.', 'a_6.', 'a_7.', 'a_11.', 'a_14.', 'a_15.']\n",
      "Action: 2\n",
      "['a_2.', 'a_6.', 'a_7.', 'a_11.', 'a_13.', 'a_14.']\n",
      "Action: 3\n",
      "Reward: -8\n",
      "Terminated: True\n",
      "Truncated: False\n"
     ]
    }
   ],
   "source": [
    "record_dct = RecordVideo(\n",
    "    dct,\n",
    "    video_folder=\"video\",\n",
    "    name_prefix=\"dct\",\n",
    "    episode_trigger=lambda x: True,\n",
    "    disable_logger=True,\n",
    ")\n",
    "obs, _ = record_dct.reset()\n",
    "\n",
    "terminated = False\n",
    "truncated = False\n",
    "reward_sum = 0\n",
    "\n",
    "new_rules = [\n",
    "    \"disj_1 :- conj_5.\",\n",
    "    \"disj_2 :- conj_4.\",\n",
    "    \"disj_3 :- not conj_6.\",\n",
    "    \"disj_3 :- conj_0.\",\n",
    "    \"conj_4 :- not a_8, not a_13.\",\n",
    "    \"conj_5 :- not a_9, a_13, not a_14.\",\n",
    "    \"conj_6 :- not a_9.\",\n",
    "    \"conj_0 :- a_11, a_13.\",\n",
    "]\n",
    "\n",
    "while not terminated and not truncated:\n",
    "    with torch.no_grad():\n",
    "        raw_img_encoding = dct_model.get_img_encoding(\n",
    "            preprocessed_obs={\n",
    "                \"image\": torch.tensor(obs[\"image\"].copy(), device=DEVICE)\n",
    "                .unsqueeze(0)\n",
    "                .float()\n",
    "            }\n",
    "        ).squeeze(0)\n",
    "    img_encoding = [\n",
    "        f\"a_{a.item()}.\" for a in torch.nonzero(raw_img_encoding > 0)\n",
    "    ]\n",
    "    print(img_encoding)\n",
    "    ctl = clingo.Control([\"--warn=none\"])\n",
    "    show_statements = [\n",
    "        f\"#show disj_{i}/0.\" for i in range(DoorCorridorEnv.get_num_actions())\n",
    "    ]\n",
    "    ctl.add(\"base\", [], \" \".join(img_encoding + show_statements + new_rules))\n",
    "    ctl.ground([(\"base\", [])])\n",
    "    with ctl.solve(yield_=True) as handle:  # type: ignore\n",
    "        all_answer_sets = [str(a) for a in handle]\n",
    "\n",
    "    if len(all_answer_sets) != 1:\n",
    "        # No model or multiple answer sets, should not happen\n",
    "        print(f\"No model or multiple answer sets when evaluating rules.\")\n",
    "        break\n",
    "\n",
    "    if all_answer_sets[0] == \"\":\n",
    "        print(f\"No output action!\")\n",
    "        break\n",
    "\n",
    "    output_classes = all_answer_sets[0].split(\" \")\n",
    "    if len(output_classes) == 0:\n",
    "        print(f\"No output action!\")\n",
    "        break\n",
    "    output_classes_set = set([int(o[5:]) for o in output_classes])\n",
    "\n",
    "    if len(output_classes_set) != 1:\n",
    "        print(f\"Output set: {output_classes_set} not exactly one item!\")\n",
    "        break\n",
    "\n",
    "    action = list(output_classes_set)[0]\n",
    "    print(f\"Action: {action}\")\n",
    "    obs, reward, terminated, truncated, _ = record_dct.step(action)\n",
    "    reward_sum += reward\n",
    "\n",
    "print(f\"Reward: {reward_sum}\")\n",
    "print(f\"Terminated: {terminated}\")\n",
    "print(f\"Truncated: {truncated}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[3]\n",
      "[2]\n",
      "[3]\n",
      "[2]\n",
      "[3]\n",
      "[2]\n",
      "[3]\n",
      "Reward: -8\n",
      "Terminated: True\n",
      "Truncated: False\n"
     ]
    }
   ],
   "source": [
    "obs, _ = record_dct.reset()\n",
    "\n",
    "terminated = False\n",
    "truncated = False\n",
    "reward_sum = 0\n",
    "\n",
    "while not terminated and not truncated:\n",
    "    with torch.no_grad():\n",
    "        actions = dct_model.get_actions(\n",
    "            preprocessed_obs={\n",
    "                \"image\": torch.tensor([obs[\"image\"]], dtype=torch.float32).to(\n",
    "                    DEVICE\n",
    "                )\n",
    "            },\n",
    "            use_argmax=True,\n",
    "            discretise_img_encoding=True,\n",
    "        )\n",
    "    actions = actions[0]\n",
    "    print(actions)\n",
    "    obs, reward, terminated, truncated, _ = record_dct.step(actions[0])\n",
    "    reward_sum += reward\n",
    "\n",
    "print(f\"Reward: {reward_sum}\")\n",
    "print(f\"Terminated: {terminated}\")\n",
    "print(f\"Truncated: {truncated}\")\n",
    "\n",
    "record_dct.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NDNF-MT on Door Corridor OT\n",
    "\n",
    "A modified version of `DoorCorridorEnv`, but to finish the environment, the\n",
    "agent must stand on the goal state and toggle it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dcot = DoorCorridorOTEnv(render_mode=\"rgb_array\")\n",
    "dcot.metadata[\"render_fps\"] = 1\n",
    "model.load_state_dict(model_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a_1.', 'a_2.', 'a_6.', 'a_8.', 'a_13.']\n",
      "['a_1.', 'a_2.', 'a_5.', 'a_6.', 'a_8.', 'a_9.', 'a_10.', 'a_13.']\n",
      "['a_2.', 'a_6.', 'a_10.']\n",
      "['a_1.', 'a_2.', 'a_5.', 'a_6.', 'a_7.', 'a_8.', 'a_9.', 'a_10.', 'a_13.', 'a_14.']\n",
      "['a_2.', 'a_6.', 'a_7.', 'a_10.', 'a_14.']\n",
      "['a_1.', 'a_2.', 'a_5.', 'a_6.', 'a_7.', 'a_8.', 'a_9.', 'a_10.', 'a_13.', 'a_14.']\n",
      "['a_2.', 'a_6.', 'a_7.', 'a_11.', 'a_14.', 'a_15.']\n",
      "['a_2.', 'a_6.', 'a_7.', 'a_11.', 'a_13.', 'a_14.']\n",
      "['a_1.', 'a_2.', 'a_6.', 'a_8.', 'a_10.', 'a_13.']\n",
      "Reward: -270\n",
      "Terminated: False\n",
      "Truncated: True\n"
     ]
    }
   ],
   "source": [
    "obs, _ = dcot.reset()\n",
    "\n",
    "terminated = False\n",
    "truncated = False\n",
    "reward_sum = 0\n",
    "\n",
    "i = 0\n",
    "while not terminated and not truncated:\n",
    "    with torch.no_grad():\n",
    "        obs_dict = {\n",
    "            \"image\": torch.tensor(obs[\"image\"].copy(), device=DEVICE)\n",
    "            .unsqueeze(0)\n",
    "            .float()\n",
    "        }\n",
    "        raw_img_encoding = model.get_img_encoding(\n",
    "            preprocessed_obs=obs_dict\n",
    "        ).squeeze(0)\n",
    "        actions = model.get_actions(\n",
    "            preprocessed_obs=obs_dict,\n",
    "            use_argmax=True,\n",
    "            discretise_img_encoding=True,\n",
    "        )\n",
    "\n",
    "    if i <= 8:\n",
    "        img_encoding = [\n",
    "            f\"a_{a.item()}.\" for a in torch.nonzero(raw_img_encoding > 0)\n",
    "        ]\n",
    "        print(img_encoding)\n",
    "\n",
    "    actions = actions[0]\n",
    "    obs, reward, terminated, truncated, _ = dcot.step(actions[0])\n",
    "    reward_sum += reward\n",
    "    i += 1\n",
    "\n",
    "print(f\"Reward: {reward_sum}\")\n",
    "print(f\"Terminated: {terminated}\")\n",
    "print(f\"Truncated: {truncated}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modified ASP rules:\n",
    "\n",
    "disj_1 :- conj_5.\n",
    "\n",
    "disj_2 :- conj_4.\n",
    "\n",
    "**disj_3 :- conj_0.**\n",
    "\n",
    "disj_3 :- not conj_6.\n",
    "\n",
    "**conj_0 :- a_8, not a_9, a_10.**\n",
    "\n",
    "conj_4 :- not a_8.\n",
    "\n",
    "conj_5 :- not a_9, **not a_10**, a_13, not a_14.\n",
    "\n",
    "conj_6 :- not a_9.\n",
    "\n",
    "\n",
    "Image encoding at each timestep:\n",
    "\n",
    "0 ['a_1.', 'a_2.', 'a_6.', 'a_8.', 'a_13.']\n",
    "\n",
    "1 ['a_1.', 'a_2.', 'a_5.', 'a_6.', 'a_8.', 'a_9.', 'a_10.', 'a_13.']\n",
    "\n",
    "2 ['a_2.', 'a_6.', 'a_10.']\n",
    "\n",
    "3 ['a_1.', 'a_2.', 'a_5.', 'a_6.', 'a_7.', 'a_8.', 'a_9.', 'a_10.', 'a_13.', 'a_14.']\n",
    "\n",
    "4 ['a_2.', 'a_6.', 'a_7.', 'a_10.', 'a_14.']\n",
    "\n",
    "5 ['a_1.', 'a_2.', 'a_5.', 'a_6.', 'a_7.', 'a_8.', 'a_9.', 'a_10.', 'a_13.', 'a_14.']\n",
    "\n",
    "6 ['a_2.', 'a_6.', 'a_7.', 'a_11.', 'a_14.', 'a_15.']\n",
    "\n",
    "7 ['a_2.', 'a_6.', 'a_7.', 'a_11.', 'a_13.', 'a_14.']\n",
    "\n",
    "8 ['a_1.', 'a_2.', 'a_6.', 'a_8.', 'a_10.', 'a_13.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a_1.', 'a_2.', 'a_6.', 'a_8.', 'a_13.']\n",
      "Action: 1\n",
      "['a_1.', 'a_2.', 'a_5.', 'a_6.', 'a_8.', 'a_9.', 'a_10.', 'a_13.']\n",
      "Action: 3\n",
      "['a_2.', 'a_6.', 'a_10.']\n",
      "Action: 2\n",
      "['a_1.', 'a_2.', 'a_5.', 'a_6.', 'a_7.', 'a_8.', 'a_9.', 'a_10.', 'a_13.', 'a_14.']\n",
      "Action: 3\n",
      "['a_2.', 'a_6.', 'a_7.', 'a_10.', 'a_14.']\n",
      "Action: 2\n",
      "['a_1.', 'a_2.', 'a_5.', 'a_6.', 'a_7.', 'a_8.', 'a_9.', 'a_10.', 'a_13.', 'a_14.']\n",
      "Action: 3\n",
      "['a_2.', 'a_6.', 'a_7.', 'a_11.', 'a_14.', 'a_15.']\n",
      "Action: 2\n",
      "['a_2.', 'a_6.', 'a_7.', 'a_11.', 'a_13.', 'a_14.']\n",
      "Action: 2\n",
      "['a_1.', 'a_2.', 'a_6.', 'a_8.', 'a_10.', 'a_13.']\n",
      "Action: 3\n"
     ]
    }
   ],
   "source": [
    "obs, _ = dcot.reset()\n",
    "\n",
    "terminated = False\n",
    "truncated = False\n",
    "reward_sum = 0\n",
    "\n",
    "new_rules = [\n",
    "    \"disj_1 :- conj_5.\",\n",
    "    \"disj_2 :- conj_4.\",\n",
    "    \"disj_3 :- conj_0.\" \"disj_3 :- not conj_6.\",\n",
    "    \"conj_0 :- a_8, not a_9, a_10.\",\n",
    "    \"conj_4 :- not a_8.\",\n",
    "    \"conj_5 :- not a_9, not a_10, a_13, not a_14.\",\n",
    "    \"conj_6 :- not a_9.\",\n",
    "]\n",
    "\n",
    "while not terminated and not truncated:\n",
    "    with torch.no_grad():\n",
    "        raw_img_encoding = model.get_img_encoding(\n",
    "            preprocessed_obs={\n",
    "                \"image\": torch.tensor(obs[\"image\"].copy(), device=DEVICE)\n",
    "                .unsqueeze(0)\n",
    "                .float()\n",
    "            }\n",
    "        ).squeeze(0)\n",
    "    img_encoding = [\n",
    "        f\"a_{a.item()}.\" for a in torch.nonzero(raw_img_encoding > 0)\n",
    "    ]\n",
    "    print(img_encoding)\n",
    "    ctl = clingo.Control([\"--warn=none\"])\n",
    "    show_statements = [\n",
    "        f\"#show disj_{i}/0.\" for i in range(DoorCorridorEnv.get_num_actions())\n",
    "    ]\n",
    "    ctl.add(\"base\", [], \" \".join(img_encoding + show_statements + new_rules))\n",
    "    ctl.ground([(\"base\", [])])\n",
    "    with ctl.solve(yield_=True) as handle:  # type: ignore\n",
    "        all_answer_sets = [str(a) for a in handle]\n",
    "\n",
    "    if len(all_answer_sets) != 1:\n",
    "        # No model or multiple answer sets, should not happen\n",
    "        print(f\"No model or multiple answer sets when evaluating rules.\")\n",
    "        break\n",
    "\n",
    "    if all_answer_sets[0] == \"\":\n",
    "        print(f\"No output action!\")\n",
    "        break\n",
    "\n",
    "    output_classes = all_answer_sets[0].split(\" \")\n",
    "    if len(output_classes) == 0:\n",
    "        print(f\"No output action!\")\n",
    "        break\n",
    "    output_classes_set = set([int(o[5:]) for o in output_classes])\n",
    "\n",
    "    if len(output_classes_set) != 1:\n",
    "        print(f\"Output set: {output_classes_set} not exactly one item!\")\n",
    "        break\n",
    "\n",
    "    action = list(output_classes_set)[0]\n",
    "    print(f\"Action: {action}\")\n",
    "    obs, reward, terminated, truncated, _ = dcot.step(action)\n",
    "    reward_sum += reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_ot_sd = deepcopy(model_state)\n",
    "modified_ot_sd[\"actor.conjunctions.weights\"][0] *= 0\n",
    "modified_ot_sd[\"actor.conjunctions.weights\"][0, 8] = 6\n",
    "modified_ot_sd[\"actor.conjunctions.weights\"][0, 9] = -6\n",
    "modified_ot_sd[\"actor.conjunctions.weights\"][0, 10] = 6\n",
    "\n",
    "modified_ot_sd[\"actor.conjunctions.weights\"][5, 10] = -6\n",
    "\n",
    "\n",
    "modified_ot_sd[\"actor.disjunctions.weights\"][3, 0] = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DCPPONDNFMutexTanhAgent(\n",
       "  (image_encoder): Sequential(\n",
       "    (0): Conv2d(2, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (1): Tanh()\n",
       "  )\n",
       "  (extra_layer): Sequential(\n",
       "    (0): Linear(in_features=36, out_features=16, bias=True)\n",
       "    (1): Tanh()\n",
       "  )\n",
       "  (actor): NeuralDNFMutexTanh(\n",
       "    (conjunctions): SemiSymbolic(in_features=16, out_features=12, layer_type=SemiSymbolicLayerType.CONJUNCTION,current_delta=1.00)\n",
       "    (disjunctions): SemiSymbolicMutexTanh(in_features=12, out_features=4, layer_type=SemiSymbolicLayerType.DISJUNCTION,current_delta=1.00)\n",
       "  )\n",
       "  (critic): Sequential(\n",
       "    (0): Linear(in_features=16, out_features=64, bias=True)\n",
       "    (1): Tanh()\n",
       "    (2): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dcot_model: DCPPONDNFMutexTanhAgent = construct_model(\n",
    "    model_cfg, # type: ignore\n",
    "    DoorCorridorEnv.get_num_actions(),\n",
    "    True,\n",
    "    single_env.observation_space[\"image\"],  # type: ignore\n",
    ")\n",
    "dcot_model.to(DEVICE)\n",
    "dcot_model.load_state_dict(modified_ot_sd)\n",
    "dcot_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward: -9\n",
      "Terminated: True\n",
      "Truncated: False\n"
     ]
    }
   ],
   "source": [
    "obs, _ = dcot.reset()\n",
    "\n",
    "terminated = False\n",
    "truncated = False\n",
    "reward_sum = 0\n",
    "\n",
    "while not terminated and not truncated:\n",
    "    with torch.no_grad():\n",
    "        actions = dcot_model.get_actions(\n",
    "            preprocessed_obs={\n",
    "                \"image\": torch.tensor([obs[\"image\"]], dtype=torch.float32).to(\n",
    "                    DEVICE\n",
    "                )\n",
    "            },\n",
    "            use_argmax=True,\n",
    "            discretise_img_encoding=True,\n",
    "        )\n",
    "    actions = actions[0]\n",
    "    obs, reward, terminated, truncated, _ = dcot.step(actions[0])\n",
    "    reward_sum += reward\n",
    "\n",
    "print(f\"Reward: {reward_sum}\")\n",
    "print(f\"Terminated: {terminated}\")\n",
    "print(f\"Truncated: {truncated}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Record the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a_1.', 'a_2.', 'a_6.', 'a_8.', 'a_13.']\n",
      "Action: 1\n",
      "['a_1.', 'a_2.', 'a_5.', 'a_6.', 'a_8.', 'a_9.', 'a_10.', 'a_13.']\n",
      "Action: 3\n",
      "['a_2.', 'a_6.', 'a_10.']\n",
      "Action: 2\n",
      "['a_1.', 'a_2.', 'a_5.', 'a_6.', 'a_7.', 'a_8.', 'a_9.', 'a_10.', 'a_13.', 'a_14.']\n",
      "Action: 3\n",
      "['a_2.', 'a_6.', 'a_7.', 'a_10.', 'a_14.']\n",
      "Action: 2\n",
      "['a_1.', 'a_2.', 'a_5.', 'a_6.', 'a_7.', 'a_8.', 'a_9.', 'a_10.', 'a_13.', 'a_14.']\n",
      "Action: 3\n",
      "['a_2.', 'a_6.', 'a_7.', 'a_11.', 'a_14.', 'a_15.']\n",
      "Action: 2\n",
      "['a_2.', 'a_6.', 'a_7.', 'a_11.', 'a_13.', 'a_14.']\n",
      "Action: 2\n",
      "['a_1.', 'a_2.', 'a_6.', 'a_8.', 'a_10.', 'a_13.']\n",
      "Action: 3\n",
      "Reward: -9\n",
      "Terminated: True\n",
      "Truncated: False\n"
     ]
    }
   ],
   "source": [
    "record_dcot = RecordVideo(\n",
    "    dcot,\n",
    "    video_folder=\"video\",\n",
    "    name_prefix=\"dcot\",\n",
    "    episode_trigger=lambda x: True,\n",
    "    disable_logger=True,\n",
    ")\n",
    "obs, _ = record_dcot.reset()\n",
    "\n",
    "terminated = False\n",
    "truncated = False\n",
    "reward_sum = 0\n",
    "\n",
    "new_rules = [\n",
    "    \"disj_1 :- conj_5.\",\n",
    "    \"disj_2 :- conj_4.\",\n",
    "    \"disj_3 :- conj_0.\" \"disj_3 :- not conj_6.\",\n",
    "    \"conj_0 :- a_8, not a_9, a_10.\",\n",
    "    \"conj_4 :- not a_8.\",\n",
    "    \"conj_5 :- not a_9, not a_10, a_13, not a_14.\",\n",
    "    \"conj_6 :- not a_9.\",\n",
    "]\n",
    "\n",
    "while not terminated and not truncated:\n",
    "    with torch.no_grad():\n",
    "        raw_img_encoding = dcot_model.get_img_encoding(\n",
    "            preprocessed_obs={\n",
    "                \"image\": torch.tensor(obs[\"image\"].copy(), device=DEVICE)\n",
    "                .unsqueeze(0)\n",
    "                .float()\n",
    "            }\n",
    "        ).squeeze(0)\n",
    "    img_encoding = [\n",
    "        f\"a_{a.item()}.\" for a in torch.nonzero(raw_img_encoding > 0)\n",
    "    ]\n",
    "    print(img_encoding)\n",
    "    ctl = clingo.Control([\"--warn=none\"])\n",
    "    show_statements = [\n",
    "        f\"#show disj_{i}/0.\" for i in range(DoorCorridorEnv.get_num_actions())\n",
    "    ]\n",
    "    ctl.add(\"base\", [], \" \".join(img_encoding + show_statements + new_rules))\n",
    "    ctl.ground([(\"base\", [])])\n",
    "    with ctl.solve(yield_=True) as handle:  # type: ignore\n",
    "        all_answer_sets = [str(a) for a in handle]\n",
    "\n",
    "    if len(all_answer_sets) != 1:\n",
    "        # No model or multiple answer sets, should not happen\n",
    "        print(f\"No model or multiple answer sets when evaluating rules.\")\n",
    "        break\n",
    "\n",
    "    if all_answer_sets[0] == \"\":\n",
    "        print(f\"No output action!\")\n",
    "        break\n",
    "\n",
    "    output_classes = all_answer_sets[0].split(\" \")\n",
    "    if len(output_classes) == 0:\n",
    "        print(f\"No output action!\")\n",
    "        break\n",
    "    output_classes_set = set([int(o[5:]) for o in output_classes])\n",
    "\n",
    "    if len(output_classes_set) != 1:\n",
    "        print(f\"Output set: {output_classes_set} not exactly one item!\")\n",
    "        break\n",
    "\n",
    "    action = list(output_classes_set)[0]\n",
    "    print(f\"Action: {action}\")\n",
    "    obs, reward, terminated, truncated, _ = record_dcot.step(action)\n",
    "    reward_sum += reward\n",
    "\n",
    "print(f\"Reward: {reward_sum}\")\n",
    "print(f\"Terminated: {terminated}\")\n",
    "print(f\"Truncated: {truncated}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[3]\n",
      "[2]\n",
      "[3]\n",
      "[2]\n",
      "[3]\n",
      "[2]\n",
      "[2]\n",
      "[3]\n",
      "Reward: -9\n",
      "Terminated: True\n",
      "Truncated: False\n"
     ]
    }
   ],
   "source": [
    "obs, _ = record_dcot.reset()\n",
    "\n",
    "terminated = False\n",
    "truncated = False\n",
    "reward_sum = 0\n",
    "\n",
    "while not terminated and not truncated:\n",
    "    with torch.no_grad():\n",
    "        actions = dcot_model.get_actions(\n",
    "            preprocessed_obs={\n",
    "                \"image\": torch.tensor([obs[\"image\"]], dtype=torch.float32).to(\n",
    "                    DEVICE\n",
    "                )\n",
    "            },\n",
    "            use_argmax=True,\n",
    "            discretise_img_encoding=True,\n",
    "        )\n",
    "    actions = actions[0]\n",
    "    print(actions)\n",
    "    obs, reward, terminated, truncated, _ = record_dcot.step(actions[0])\n",
    "    reward_sum += reward\n",
    "\n",
    "print(f\"Reward: {reward_sum}\")\n",
    "print(f\"Terminated: {terminated}\")\n",
    "print(f\"Truncated: {truncated}\")\n",
    "\n",
    "record_dcot.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display the recorded videos\n",
    "\n",
    "The videos are renamed to represent the environment and the model type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"video/dct-6731-asp.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DCT with ASP policy\n",
    "# Actions: 1, 3, 2, 3, 2, 3, 2, 3\n",
    "Video(\"video/dct-6731-asp.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"video/dct-6731-ndnf-mt.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DCT with NDNF-MT policy\n",
    "# Actions: 1, 3, 2, 3, 2, 3, 2, 3\n",
    "Video(\"video/dct-6731-ndnf-mt.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"video/dcot-6731-asp.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DCOT with ASP policy\n",
    "# Actions: 1, 3, 2, 3, 2, 3, 2, 2, 3\n",
    "Video(\"video/dcot-6731-asp.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"video/dcot-6731-ndnf-mt.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DCOT with NDNF-MT policy\n",
    "# Actions: 1, 3, 2, 3, 2, 3, 2, 2, 3\n",
    "Video(\"video/dcot-6731-ndnf-mt.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
