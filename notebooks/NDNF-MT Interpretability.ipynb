{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpret NDNF-MT with Logic-based Programming\n",
    "\n",
    "We take the output from experiment `sc_ws_ppo_ndnf_mt_l4_1e5_aux_2151` on\n",
    "`SmallCorridorEnv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from neural_dnf.neural_dnf import NeuralDNFMutexTanh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thresholded sc_ws_ppo_ndnf_mt_l4_1e5_aux_2151\n",
    "\n",
    "Threshold upper bound: 0.67\n",
    "\n",
    "Best threshold: 0.5299999713897705\n",
    "\n",
    "KL divergence: 0.01657593995332718\n",
    "\n",
    "After 2nd Prune\n",
    "\n",
    "Action distribution: tensor([[0.6590, 0.3410], [0.0413, 0.9587], [0.8226, 0.1774]])\n",
    "\n",
    "KL divergence cmp to after prune: 0.01657593995332718\n",
    "\n",
    "Model:\n",
    "\n",
    "Conjunction: tensor([[ 6., -0.], [ 6., -6.], [-0.,  6.], [ 6., -0.]])\n",
    "\n",
    "Disjunction: tensor([[-0.0000, -0.0000,  0.1501, -0.5853], [ 0.6486,  0.3062, -0.2876,  0.3611]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"sc_ws_ppo_ndnf_mt_l4_1e5_aux_2151\"\n",
    "conjunction_tensor = torch.Tensor(([[ 6., -0.], [ 6., -6.], [-0.,  6.], [ 6., -0.]]))\n",
    "disjunction_tensor = torch.Tensor([[-0.0000, -0.0000,  0.1501, -0.5853], [ 0.6486,  0.3062, -0.2876,  0.3611]])\n",
    "\n",
    "ndnf_mt = NeuralDNFMutexTanh(\n",
    "    num_preds = conjunction_tensor.shape[1],\n",
    "    num_conjuncts=conjunction_tensor.shape[0],\n",
    "    n_out=disjunction_tensor.shape[0],\n",
    "    delta=1.0\n",
    ")\n",
    "ndnf_mt.conjunctions.weights.data = conjunction_tensor\n",
    "ndnf_mt.disjunctions.weights.data = disjunction_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_possible_inputs = torch.Tensor([\n",
    "    [1, -1],    # left wall, right no wall\n",
    "    [-1, -1],   # \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method\n",
    "\n",
    "Step 1: Prune the model\n",
    "\n",
    "Step 2: Compute deterministic conjunction via thresholding\n",
    "\n",
    "Step 3: Re-prune the model\n",
    "\n",
    "Step 4: Raw enumeration of the disjunctions\n",
    "\n",
    "-  This step needs to compute the bias of the disjunction layer\n",
    "\n",
    "Step 5: Condensation via logical equivalence\n",
    "\n",
    "Step 6: Rule simplification based on experienced observations\n",
    "\n",
    "Step 7: Interpretation of conjunction based on experienced observations\n",
    "\n",
    "Step 8: ProbLog rules with annotated disjunction based on experienced observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1501, 0.9549])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 4: Raw enmueration of the layers\n",
    "# compute the bias of the disjunction layer\n",
    "\n",
    "abs_weight = torch.abs(disjunction_tensor)\n",
    "# abs_weight: Q x P\n",
    "max_abs_w = torch.max(abs_weight, dim=1)[0]\n",
    "# max_abs_w: Q\n",
    "sum_abs_w = torch.sum(abs_weight, dim=1)\n",
    "# sum_abs_w: Q\n",
    "bias = sum_abs_w - max_abs_w\n",
    "# bias: Q\n",
    "bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method applied sc_ws_ppo_ndnf_mt_l4_1e5_aux_2151\n",
    "\n",
    "`disj_0` is `turn_left`, and `disj_1` is `turn_right`.\n",
    "\n",
    "`conj_0 :- left_wall.`\n",
    "\n",
    "`conj_1 :- left_wall, not right_wall.`\n",
    "\n",
    "`conj_2 :- right_wall.`\n",
    "\n",
    "`conj_3 :- left_wall.`\n",
    "\n",
    "**Step 4: Raw enumeration of the disjunctions**\n",
    "\n",
    "```prolog\n",
    "disj_0 = 0.1501 * conj_2 - 0.5853 * conj_3 + 0.1501.\n",
    "\n",
    "disj_1 = 0.6486 * conj_0 + 0.3062 * conj_1 - 0.2876 * conj_2 + 0.3611 * conj_3 + 0.9549.\n",
    "```\n",
    "\n",
    "**Step 5: Condensation via logical equivalence**\n",
    "\n",
    "`conj_0` and `conj_3` are equivalent. We replace `conj_3` with `conj_0`.\n",
    "\n",
    "```prolog\n",
    "disj_0 = 0.1501 * conj_2 - 0.5853 * conj_0 + 0.1501.\n",
    "\n",
    "disj_1 = 0.6486 * conj_0 + 0.3062 * conj_1 - 0.2876 * conj_2 + 0.3611 * conj_0 + 0.9549\n",
    "\n",
    "       = 1.0097 * conj_0 + 0.3062 * conj_1 - 0.2876 * conj_2 + 0.9549.\n",
    "```\n",
    "\n",
    "**Step 6: Rule simplification based on experienced observations**\n",
    "\n",
    "`not right_wall` is always true and `right_wall` is always false.\n",
    "\n",
    "`conj_1` is equivalent to `conj_1 :- left_wall` and thus is equivalent to `conj_0`.\n",
    "\n",
    "`conj_2` is thus never true will always gives -1.\n",
    "\n",
    "```prolog\n",
    "disj_0 = 0.1501 * (-1) - 0.5853 * conj_0 + 0.1501\n",
    "\n",
    "       = -0.5853 * conj_0.\n",
    "\n",
    "disj_1 = 1.0097 * conj_0 + 0.3062 * conj_0 - 0.2876 * (-1) + 0.9549\n",
    "\n",
    "       = 1.3159 * conj_0 + 1.2425.\n",
    "```\n",
    "\n",
    "**Step 7: Interpretation of conjunction based on experienced observations**\n",
    "\n",
    "`conj_0` is equivalent to `left_wall`.\n",
    "\n",
    "```prolog\n",
    "disj_0 = -0.5853 * left_wall.\n",
    "\n",
    "disj_1 = 1.3159 * left_wall + 1.2425.\n",
    "```\n",
    "\n",
    "**Step 8: ProbLog rules with annotated disjunction based on experienced observations**\n",
    "\n",
    "Input: [1, -1] (`left_wall`, `-right_wall`)\n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    "disj_0 = -0.583, disj_1 = 2.5584\n",
    "\n",
    "tanh([disj_0, disj_1]) = [-0.5265,  0.9881]\n",
    "\n",
    "mutex_tanh([disj_0, disj_1]) = [-0.9173,  0.9173]\n",
    "\n",
    "prob([disj_0, disj_1]) = [0.0413, 0.9587]\n",
    "\n",
    "```\n",
    "\n",
    "Input: [-1, -1] (`-left_wall`, `-right_wall`)\n",
    "\n",
    "```python\n",
    "\n",
    "disj_0 = 0.5853, disj_1 = -0.0734\n",
    "\n",
    "tanh([disj_0, disj_1]) = [0.5265, -0.0733]\n",
    "\n",
    "mutex_tanh([disj_0, disj_1]) = [0.3179, -0.3179]\n",
    "\n",
    "prob([disj_0, disj_1]) = [0.6590, 0.3410]\n",
    "\n",
    "```\n",
    "\n",
    "Covert to Problog rule:\n",
    "\n",
    "```prolog\n",
    "\n",
    "rule_1 :- left_wall.\n",
    "\n",
    "0.0413::turn_left; 0.9587::turn_right :- rule_1.\n",
    "\n",
    "rule_2 :- not left_wall.\n",
    "\n",
    "0.6590::turn_left; 0.3410::turn_right :- rule_2.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'conjunction': {'raw': tensor([[ 6.,  6., -6.,  6.],\n",
      "        [-6., -6., -6., -6.]]), 'tanh': tensor([[ 1.0000,  1.0000, -1.0000,  1.0000],\n",
      "        [-1.0000, -1.0000, -1.0000, -1.0000]])}, 'disjunction': {'raw': tensor([[-0.5853,  2.5584],\n",
      "        [ 0.5853, -0.0734]]), 'tanh': tensor([[-0.5265,  0.9881],\n",
      "        [ 0.5265, -0.0733]]), 'mutex_tanh': tensor([[-0.9173,  0.9173],\n",
      "        [ 0.3179, -0.3179]])}}\n",
      "tensor([[0.0413, 0.9587],\n",
      "        [0.6590, 0.3410]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    out_dict = ndnf_mt.get_all_forms(all_possible_inputs)\n",
    "print(out_dict)\n",
    "prob = (out_dict[\"disjunction\"][\"mutex_tanh\"] + 1) / 2\n",
    "print(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
